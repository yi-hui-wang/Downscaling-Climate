{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8de151-a6d2-4d9b-8ba4-59a02d3977f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modified version of Hyperparameter-Tuning-CNN-Gamma-Nonlinear-Taiwan.ipynb\n",
    "### Use three dynamic variables identified to generate best performance in InputVariable-Model-Evaluation-CNNGamma-Taiwan.ipynb\n",
    "### created by yhw on 1/13/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809331e1-5695-47ad-a57b-a0f012ee2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 06:31:32.307611: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-14 06:31:32.348489: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-14 06:31:32.349572: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 06:31:33.086746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import cartopy.crs as ccrs\n",
    "from dask.diagnostics import ProgressBar\n",
    "import cmocean\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Set working paths\n",
    "sys.path.append(r'/home/u1281808/High-res-interpretable-dl/src')\n",
    "os.chdir(r'/home/u1281808/High-res-interpretable-dl')\n",
    "\n",
    "from models import train_model, complex_conv\n",
    "from losses import gamma_loss_1d, gamma_mse_metric\n",
    "from prepare_data_Taiwan import prepare_training_dataset, create_test_train_split\n",
    "\n",
    "# Set random seeds\n",
    "tf.random.set_seed(2)\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86640f81-9e69-4ad7-99c8-ae0412f44e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 407.41 ms\n",
      "[########################################] | 100% Completed | 1.13 sms\n",
      "[########################################] | 100% Completed | 102.44 ms\n",
      "[########################################] | 100% Completed | 304.47 ms\n",
      "[########################################] | 100% Completed | 102.47 ms\n",
      "[########################################] | 100% Completed | 405.95 ms\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter ranges\n",
    "layer_neuron_map = {\n",
    "    3: [16, 32, 64],\n",
    "    4: [16, 32, 64, 128],\n",
    "    5: [16, 32, 64, 128, 256]\n",
    "}\n",
    "kernel_size_options = [(3, 3), (5, 5), (7, 7)]\n",
    "learning_rate_options = [1e-5, 1e-4, 1e-3]  # 1e-2 may give too big validation MSE\n",
    "dropout_options = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "batch_size_options = [16, 32, 64]\n",
    "\n",
    "# Configuration for data preparation\n",
    "config = dict(\n",
    "    y=\"/home/u1281808/High-res-interpretable-dl/training_data/combined_TReAD_daily_RAINNC_19802021.nc\",\n",
    "    X=\"/home/u1281808/High-res-interpretable-dl/training_data/combination.nc\",\n",
    "    train_start=\"1981-01-01\",\n",
    "    train_end=\"2010-12-31\",\n",
    "    val_start=\"2011-01-01\",\n",
    "    val_end=\"2015-12-31\",\n",
    "    test_start=\"2016-01-01\",\n",
    "    test_end=\"2021-12-31\",\n",
    "    downscale_variables=['u850', 'v850', 'w850']\n",
    ")\n",
    "\n",
    "\n",
    "# Prepare datasets\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = create_test_train_split(config)\n",
    "x_train, x_test, x_val, y_train, y_test, y_val = prepare_training_dataset(\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test\n",
    ")\n",
    "\n",
    "\n",
    "x_train_np, x_val_np, x_test_np = x_train.values, x_val.values, x_test.values\n",
    "y_train_np, y_val_np, y_test_np = y_train['pr'].values, y_val['pr'].values, y_test['pr'].values\n",
    "\n",
    "input_shape = x_train_np.shape[1:]\n",
    "output_shape = y_train_np.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e11322-64b5-4920-92dd-d43d6999820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 33, 37, 16)           448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 16, 18, 16)           0         ['conv2d[0][0]']              \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 16, 18, 16)           64        ['average_pooling2d[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 16, 18, 32)           4640      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 8, 9, 32)             0         ['conv2d_1[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 8, 9, 32)             128       ['average_pooling2d_1[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 8, 9, 64)             18496     ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (Avera  (None, 4, 4, 64)             0         ['conv2d_2[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 4, 4, 64)             256       ['average_pooling2d_2[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1024)                 0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  262400    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 17473)                4490561   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 17473)                4490561   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 17473)                4490561   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 17473)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 17473)             0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 17473)             0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 3, 17473)             0         ['reshape[0][0]',             \n",
      "                                                                     'reshape_1[0][0]',           \n",
      "                                                                     'reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13758115 (52.48 MB)\n",
      "Trainable params: 13757891 (52.48 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 06:31:47.127246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-01-14 06:31:47.144357: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1794] (One-time warning): Not using XLA:CPU for cluster.\n",
      "\n",
      "If you want XLA:CPU, do one of the following:\n",
      "\n",
      " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
      " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
      " - use experimental_jit_scope, or\n",
      " - use tf.function(jit_compile=True).\n",
      "\n",
      "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
      "proper command-line flag, not via TF_XLA_FLAGS).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "684/684 [==============================] - 47s 67ms/step - loss: 0.3479 - gamma_mse_metric: 0.8787 - val_loss: 0.2709 - val_gamma_mse_metric: 0.7217 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.1727 - gamma_mse_metric: 0.7521 - val_loss: 0.2449 - val_gamma_mse_metric: 0.6399 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "684/684 [==============================] - 45s 65ms/step - loss: 0.1331 - gamma_mse_metric: 0.6808 - val_loss: 0.2343 - val_gamma_mse_metric: 0.5508 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.1163 - gamma_mse_metric: 0.6224 - val_loss: 0.2296 - val_gamma_mse_metric: 0.6309 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.1063 - gamma_mse_metric: 0.5922 - val_loss: 0.2222 - val_gamma_mse_metric: 1.4238 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.1043 - gamma_mse_metric: 0.5984 - val_loss: 0.2178 - val_gamma_mse_metric: 1.7388 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0965 - gamma_mse_metric: 0.5987 - val_loss: 0.2132 - val_gamma_mse_metric: 2.4562 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0995 - gamma_mse_metric: 0.6025 - val_loss: 0.2057 - val_gamma_mse_metric: 2.8855 - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0965 - gamma_mse_metric: 0.6009 - val_loss: 0.2030 - val_gamma_mse_metric: 3.3911 - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0886 - gamma_mse_metric: 0.5967 - val_loss: 0.2046 - val_gamma_mse_metric: 4.6214 - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.0850 - gamma_mse_metric: 0.6307 - val_loss: 0.1994 - val_gamma_mse_metric: 4.0410 - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0821 - gamma_mse_metric: 0.6215 - val_loss: 0.1958 - val_gamma_mse_metric: 3.7641 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0825 - gamma_mse_metric: 0.6336 - val_loss: 0.1978 - val_gamma_mse_metric: 3.5326 - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0809 - gamma_mse_metric: 0.6450 - val_loss: 0.1949 - val_gamma_mse_metric: 2.4693 - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0804 - gamma_mse_metric: 0.6424 - val_loss: 0.1985 - val_gamma_mse_metric: 5.4026 - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "684/684 [==============================] - 44s 64ms/step - loss: 0.0782 - gamma_mse_metric: 0.6477 - val_loss: 0.1932 - val_gamma_mse_metric: 5.2002 - lr: 1.0000e-05\n",
      "Epoch 17/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0776 - gamma_mse_metric: 0.6268 - val_loss: 0.1961 - val_gamma_mse_metric: 4.3401 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.0746 - gamma_mse_metric: 0.6483 - val_loss: 0.2000 - val_gamma_mse_metric: 7.8504 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "684/684 [==============================] - 45s 65ms/step - loss: 0.0755 - gamma_mse_metric: 0.6774 - val_loss: 0.1939 - val_gamma_mse_metric: 8.6201 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "684/684 [==============================] - 45s 65ms/step - loss: 0.0782 - gamma_mse_metric: 0.6636 - val_loss: 0.1920 - val_gamma_mse_metric: 6.0204 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0779 - gamma_mse_metric: 0.6500 - val_loss: 0.1914 - val_gamma_mse_metric: 5.1668 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0772 - gamma_mse_metric: 0.6588 - val_loss: 0.1909 - val_gamma_mse_metric: 4.3071 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "684/684 [==============================] - 44s 64ms/step - loss: 0.0750 - gamma_mse_metric: 0.6456 - val_loss: 0.1920 - val_gamma_mse_metric: 5.9400 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0746 - gamma_mse_metric: 0.6806 - val_loss: 0.1951 - val_gamma_mse_metric: 6.9700 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.0737 - gamma_mse_metric: 0.6759 - val_loss: 0.1974 - val_gamma_mse_metric: 8.3993 - lr: 1.0000e-05\n",
      "Epoch 26/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0740 - gamma_mse_metric: 0.6586 - val_loss: 0.1906 - val_gamma_mse_metric: 5.3023 - lr: 1.0000e-05\n",
      "Epoch 27/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0758 - gamma_mse_metric: 0.6742 - val_loss: 0.1918 - val_gamma_mse_metric: 6.7293 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "684/684 [==============================] - 44s 65ms/step - loss: 0.0728 - gamma_mse_metric: 0.6814 - val_loss: 0.1950 - val_gamma_mse_metric: 5.3958 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "684/684 [==============================] - 45s 65ms/step - loss: 0.0716 - gamma_mse_metric: 0.6619 - val_loss: 0.1967 - val_gamma_mse_metric: 8.8443 - lr: 1.0000e-05\n",
      "Epoch 30/40\n",
      "684/684 [==============================] - 45s 66ms/step - loss: 0.0705 - gamma_mse_metric: 0.6778 - val_loss: 0.1965 - val_gamma_mse_metric: 4.4718 - lr: 1.0000e-05\n",
      "Epoch 31/40\n",
      "684/684 [==============================] - 46s 67ms/step - loss: 0.0692 - gamma_mse_metric: 0.6682 - val_loss: 0.1983 - val_gamma_mse_metric: 9.1081 - lr: 1.0000e-05\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 33, 37, 16)           1216      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (Avera  (None, 16, 18, 16)           0         ['conv2d_3[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 16, 18, 16)           64        ['average_pooling2d_3[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 16, 18, 32)           12832     ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (Avera  (None, 8, 9, 32)             0         ['conv2d_4[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 8, 9, 32)             128       ['average_pooling2d_4[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 8, 9, 64)             51264     ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (Avera  (None, 4, 4, 64)             0         ['conv2d_5[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 4, 4, 64)             256       ['average_pooling2d_5[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            204928    ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (Avera  (None, 2, 2, 128)            0         ['conv2d_6[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 2, 2, 128)            512       ['average_pooling2d_6[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 512)                  0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 256)                  131328    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 17473)                4490561   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 17473)                4490561   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 17473)                4490561   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 1, 17473)             0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)         (None, 1, 17473)             0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)         (None, 1, 17473)             0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 3, 17473)             0         ['reshape_3[0][0]',           \n",
      " )                                                                   'reshape_4[0][0]',           \n",
      "                                                                     'reshape_5[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13874211 (52.93 MB)\n",
      "Trainable params: 13873731 (52.92 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 25s 138ms/step - loss: 0.0881 - gamma_mse_metric: 0.9322 - val_loss: 0.1943 - val_gamma_mse_metric: 18.0567 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 22s 131ms/step - loss: 0.0553 - gamma_mse_metric: 1.5109 - val_loss: 0.2041 - val_gamma_mse_metric: 13654.0293 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 22s 131ms/step - loss: 0.0599 - gamma_mse_metric: 3.1842 - val_loss: 0.1702 - val_gamma_mse_metric: 250.5709 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 22s 130ms/step - loss: 0.0522 - gamma_mse_metric: 1.6301 - val_loss: 0.1914 - val_gamma_mse_metric: 21.2532 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 22s 131ms/step - loss: 0.0537 - gamma_mse_metric: 3.1275 - val_loss: 0.1915 - val_gamma_mse_metric: 51.9875 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 23s 132ms/step - loss: 0.0581 - gamma_mse_metric: 1.1881 - val_loss: 0.1662 - val_gamma_mse_metric: 6222.8735 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 23s 132ms/step - loss: 0.0572 - gamma_mse_metric: 2.8694 - val_loss: 0.1917 - val_gamma_mse_metric: 1065.9451 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 22s 131ms/step - loss: 0.0505 - gamma_mse_metric: 4.7109 - val_loss: 0.1737 - val_gamma_mse_metric: 1295.4573 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 22s 130ms/step - loss: 0.0536 - gamma_mse_metric: 6.8673 - val_loss: 0.1817 - val_gamma_mse_metric: 108.4222 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "171/171 [==============================] - 22s 130ms/step - loss: 0.0382 - gamma_mse_metric: 2.4888 - val_loss: 0.1816 - val_gamma_mse_metric: 257.3185 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 22s 130ms/step - loss: 0.0370 - gamma_mse_metric: 4.3293 - val_loss: 0.1724 - val_gamma_mse_metric: 63.9544 - lr: 2.0000e-04\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 33, 37, 16)           1216      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (Avera  (None, 16, 18, 16)           0         ['conv2d_7[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 16, 18, 16)           64        ['average_pooling2d_7[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 16, 18, 32)           12832     ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (Avera  (None, 8, 9, 32)             0         ['conv2d_8[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 8, 9, 32)             128       ['average_pooling2d_8[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 8, 9, 64)             51264     ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (Avera  (None, 4, 4, 64)             0         ['conv2d_9[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 4, 4, 64)             256       ['average_pooling2d_9[0][0]'] \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 128)            204928    ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d_10 (Aver  (None, 2, 2, 128)            0         ['conv2d_10[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 2, 2, 128)            512       ['average_pooling2d_10[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 256)            819456    ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_11 (Aver  (None, 1, 1, 256)            0         ['conv2d_11[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 1, 1, 256)            1024      ['average_pooling2d_11[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 256)                  0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 256)                  0         ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 256)                  65792     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 17473)                4490561   ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 17473)                4490561   ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 17473)                4490561   ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)         (None, 1, 17473)             0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)         (None, 1, 17473)             0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)         (None, 1, 17473)             0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 3, 17473)             0         ['reshape_6[0][0]',           \n",
      " )                                                                   'reshape_7[0][0]',           \n",
      "                                                                     'reshape_8[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14629155 (55.81 MB)\n",
      "Trainable params: 14628163 (55.80 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "342/342 [==============================] - 44s 124ms/step - loss: 0.1070 - gamma_mse_metric: 1.2286 - val_loss: 0.2487 - val_gamma_mse_metric: 30724510.0000 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "342/342 [==============================] - 42s 121ms/step - loss: 0.0837 - gamma_mse_metric: 9.5670 - val_loss: 0.2095 - val_gamma_mse_metric: 690072.6250 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "342/342 [==============================] - 42s 122ms/step - loss: 0.0796 - gamma_mse_metric: 5.3327 - val_loss: 0.1940 - val_gamma_mse_metric: 81.9197 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "342/342 [==============================] - 42s 122ms/step - loss: 0.0759 - gamma_mse_metric: 10.0632 - val_loss: 0.2079 - val_gamma_mse_metric: 13923324.0000 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "342/342 [==============================] - 42s 122ms/step - loss: 0.0769 - gamma_mse_metric: 7.8381 - val_loss: 0.1882 - val_gamma_mse_metric: 138614.3906 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "342/342 [==============================] - 42s 122ms/step - loss: 0.0776 - gamma_mse_metric: 3.8600 - val_loss: 0.2013 - val_gamma_mse_metric: 2269.8723 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "342/342 [==============================] - 42s 124ms/step - loss: 0.0746 - gamma_mse_metric: 6.5585 - val_loss: 0.2215 - val_gamma_mse_metric: 225400.4688 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "342/342 [==============================] - 42s 123ms/step - loss: 0.0707 - gamma_mse_metric: 3.5469 - val_loss: 0.1994 - val_gamma_mse_metric: 35667.1992 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "342/342 [==============================] - 42s 123ms/step - loss: 0.0627 - gamma_mse_metric: 5.3118 - val_loss: 0.2005 - val_gamma_mse_metric: 1227.8861 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "342/342 [==============================] - 42s 124ms/step - loss: 0.0585 - gamma_mse_metric: 3.4697 - val_loss: 0.2132 - val_gamma_mse_metric: 1292.2047 - lr: 2.0000e-04\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 33, 37, 16)           1216      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (Aver  (None, 16, 18, 16)           0         ['conv2d_12[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_12[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 16, 18, 32)           12832     ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (Aver  (None, 8, 9, 32)             0         ['conv2d_13[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_13[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 8, 9, 64)             51264     ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (Aver  (None, 4, 4, 64)             0         ['conv2d_14[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_14[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 1024)                 0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 1024)                 0         ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 256)                  262400    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 17473)                4490561   ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 17473)                4490561   ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 17473)                4490561   ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)         (None, 1, 17473)             0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)        (None, 1, 17473)             0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)        (None, 1, 17473)             0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 3, 17473)             0         ['reshape_9[0][0]',           \n",
      " )                                                                   'reshape_10[0][0]',          \n",
      "                                                                     'reshape_11[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13799843 (52.64 MB)\n",
      "Trainable params: 13799619 (52.64 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "342/342 [==============================] - 32s 91ms/step - loss: 0.1383 - gamma_mse_metric: 0.7008 - val_loss: 0.1921 - val_gamma_mse_metric: 0.6330 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "342/342 [==============================] - 30s 89ms/step - loss: 0.0669 - gamma_mse_metric: 0.6632 - val_loss: 0.1934 - val_gamma_mse_metric: 3.1009 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0683 - gamma_mse_metric: 0.7808 - val_loss: 0.1833 - val_gamma_mse_metric: 1.1066 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0623 - gamma_mse_metric: 0.7290 - val_loss: 0.1801 - val_gamma_mse_metric: 9.4396 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "342/342 [==============================] - 30s 88ms/step - loss: 0.0593 - gamma_mse_metric: 0.8485 - val_loss: 0.1688 - val_gamma_mse_metric: 9.7972 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0599 - gamma_mse_metric: 0.8398 - val_loss: 0.1546 - val_gamma_mse_metric: 3.2119 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "342/342 [==============================] - 30s 88ms/step - loss: 0.0599 - gamma_mse_metric: 0.8413 - val_loss: 0.1604 - val_gamma_mse_metric: 3.4109 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0550 - gamma_mse_metric: 0.8577 - val_loss: 0.1809 - val_gamma_mse_metric: 18.3004 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0551 - gamma_mse_metric: 1.1023 - val_loss: 0.1638 - val_gamma_mse_metric: 2.1979 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0502 - gamma_mse_metric: 0.7960 - val_loss: 0.1648 - val_gamma_mse_metric: 8.0135 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0492 - gamma_mse_metric: 0.8481 - val_loss: 0.1636 - val_gamma_mse_metric: 6.8533 - lr: 2.0000e-05\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 33, 37, 16)           2368      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_15 (Aver  (None, 16, 18, 16)           0         ['conv2d_15[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_15[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 16, 18, 32)           25120     ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (Aver  (None, 8, 9, 32)             0         ['conv2d_16[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_16[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 8, 9, 64)             100416    ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (Aver  (None, 4, 4, 64)             0         ['conv2d_17[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_17[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 1024)                 0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 1024)                 0         ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 256)                  262400    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 17473)                4490561   ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 17473)                4490561   ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 17473)                4490561   ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)        (None, 1, 17473)             0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)        (None, 1, 17473)             0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)        (None, 1, 17473)             0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 3, 17473)             0         ['reshape_12[0][0]',          \n",
      " )                                                                   'reshape_13[0][0]',          \n",
      "                                                                     'reshape_14[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13862435 (52.88 MB)\n",
      "Trainable params: 13862211 (52.88 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "684/684 [==============================] - 54s 77ms/step - loss: 0.3076 - gamma_mse_metric: 0.8415 - val_loss: 0.2783 - val_gamma_mse_metric: 0.6923 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.1546 - gamma_mse_metric: 0.7222 - val_loss: 0.2505 - val_gamma_mse_metric: 0.6140 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.1163 - gamma_mse_metric: 0.6603 - val_loss: 0.2378 - val_gamma_mse_metric: 0.5349 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.1009 - gamma_mse_metric: 0.6306 - val_loss: 0.2293 - val_gamma_mse_metric: 0.6627 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.0925 - gamma_mse_metric: 0.6308 - val_loss: 0.2173 - val_gamma_mse_metric: 1.0450 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "684/684 [==============================] - 51s 75ms/step - loss: 0.0902 - gamma_mse_metric: 0.6393 - val_loss: 0.2170 - val_gamma_mse_metric: 0.9957 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "684/684 [==============================] - 51s 75ms/step - loss: 0.0841 - gamma_mse_metric: 0.6389 - val_loss: 0.2152 - val_gamma_mse_metric: 1.1225 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "684/684 [==============================] - 51s 75ms/step - loss: 0.0836 - gamma_mse_metric: 0.6481 - val_loss: 0.2067 - val_gamma_mse_metric: 1.3948 - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.0836 - gamma_mse_metric: 0.6492 - val_loss: 0.2143 - val_gamma_mse_metric: 2.2921 - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "684/684 [==============================] - 51s 74ms/step - loss: 0.0776 - gamma_mse_metric: 0.6516 - val_loss: 0.2171 - val_gamma_mse_metric: 4.0795 - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "684/684 [==============================] - 51s 75ms/step - loss: 0.0701 - gamma_mse_metric: 0.6665 - val_loss: 0.2137 - val_gamma_mse_metric: 3.7334 - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "684/684 [==============================] - 52s 76ms/step - loss: 0.0717 - gamma_mse_metric: 0.6568 - val_loss: 0.2129 - val_gamma_mse_metric: 3.4680 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "684/684 [==============================] - 52s 75ms/step - loss: 0.0701 - gamma_mse_metric: 0.6714 - val_loss: 0.2098 - val_gamma_mse_metric: 2.6068 - lr: 1.0000e-05\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 33, 37, 16)           2368      ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_18 (Aver  (None, 16, 18, 16)           0         ['conv2d_18[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_18[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 16, 18, 32)           25120     ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_19 (Aver  (None, 8, 9, 32)             0         ['conv2d_19[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_19[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 8, 9, 64)             100416    ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (Aver  (None, 4, 4, 64)             0         ['conv2d_20[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_20[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 1024)                 0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 1024)                 0         ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 256)                  262400    ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 17473)                4490561   ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 17473)                4490561   ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 17473)                4490561   ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_15 (Reshape)        (None, 1, 17473)             0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_16 (Reshape)        (None, 1, 17473)             0         ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_17 (Reshape)        (None, 1, 17473)             0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 3, 17473)             0         ['reshape_15[0][0]',          \n",
      " )                                                                   'reshape_16[0][0]',          \n",
      "                                                                     'reshape_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13862435 (52.88 MB)\n",
      "Trainable params: 13862211 (52.88 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 27s 151ms/step - loss: 0.0903 - gamma_mse_metric: 0.8367 - val_loss: 0.2116 - val_gamma_mse_metric: 13.7022 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0613 - gamma_mse_metric: 10.9836 - val_loss: 0.2040 - val_gamma_mse_metric: 172.7095 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0573 - gamma_mse_metric: 4.5513 - val_loss: 0.1855 - val_gamma_mse_metric: 12.7534 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0544 - gamma_mse_metric: 3.0874 - val_loss: 0.1927 - val_gamma_mse_metric: 327.5581 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0536 - gamma_mse_metric: 1.5172 - val_loss: 0.1890 - val_gamma_mse_metric: 1.0535 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0574 - gamma_mse_metric: 1.1319 - val_loss: 0.1599 - val_gamma_mse_metric: 3791.5474 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 25s 145ms/step - loss: 0.0561 - gamma_mse_metric: 15.9683 - val_loss: 0.1833 - val_gamma_mse_metric: 1704.1085 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0490 - gamma_mse_metric: 2.3573 - val_loss: 0.1742 - val_gamma_mse_metric: 3505.5149 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0532 - gamma_mse_metric: 7.5294 - val_loss: 0.1611 - val_gamma_mse_metric: 180.4615 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0390 - gamma_mse_metric: 3.4354 - val_loss: 0.1642 - val_gamma_mse_metric: 230.8256 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0373 - gamma_mse_metric: 2.5926 - val_loss: 0.1556 - val_gamma_mse_metric: 23.9478 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0422 - gamma_mse_metric: 1.5609 - val_loss: 0.1566 - val_gamma_mse_metric: 10.9340 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0388 - gamma_mse_metric: 1.5614 - val_loss: 0.1590 - val_gamma_mse_metric: 15.8270 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "171/171 [==============================] - 26s 150ms/step - loss: 0.0356 - gamma_mse_metric: 1.6868 - val_loss: 0.1607 - val_gamma_mse_metric: 10.1852 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0340 - gamma_mse_metric: 1.4601 - val_loss: 0.1605 - val_gamma_mse_metric: 9.4441 - lr: 4.0000e-05\n",
      "Epoch 16/40\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0376 - gamma_mse_metric: 1.7026 - val_loss: 0.1613 - val_gamma_mse_metric: 8.3687 - lr: 4.0000e-05\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 33, 37, 16)           1216      ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (Aver  (None, 16, 18, 16)           0         ['conv2d_21[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_21[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 16, 18, 32)           12832     ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (Aver  (None, 8, 9, 32)             0         ['conv2d_22[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_22[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 8, 9, 64)             51264     ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (Aver  (None, 4, 4, 64)             0         ['conv2d_23[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_23[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 4, 4, 128)            204928    ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_24 (Aver  (None, 2, 2, 128)            0         ['conv2d_24[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 2, 2, 128)            512       ['average_pooling2d_24[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 512)                  0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 512)                  0         ['flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 256)                  131328    ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 17473)                4490561   ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 17473)                4490561   ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 17473)                4490561   ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_18 (Reshape)        (None, 1, 17473)             0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_19 (Reshape)        (None, 1, 17473)             0         ['dense_26[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_20 (Reshape)        (None, 1, 17473)             0         ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 3, 17473)             0         ['reshape_18[0][0]',          \n",
      " )                                                                   'reshape_19[0][0]',          \n",
      "                                                                     'reshape_20[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13874211 (52.93 MB)\n",
      "Trainable params: 13873731 (52.92 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "342/342 [==============================] - 33s 93ms/step - loss: 0.1034 - gamma_mse_metric: 1.4909 - val_loss: 0.1860 - val_gamma_mse_metric: 29403.8418 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "342/342 [==============================] - 30s 89ms/step - loss: 0.0814 - gamma_mse_metric: 8.2990 - val_loss: 0.2041 - val_gamma_mse_metric: 799795.3125 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "342/342 [==============================] - 30s 89ms/step - loss: 0.0796 - gamma_mse_metric: 57.9860 - val_loss: 0.1982 - val_gamma_mse_metric: 22.5623 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0717 - gamma_mse_metric: 6.0828 - val_loss: 0.2098 - val_gamma_mse_metric: 133.5052 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0646 - gamma_mse_metric: 3.0948 - val_loss: 0.1909 - val_gamma_mse_metric: 217.1986 - lr: 2.0000e-04\n",
      "Epoch 6/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0632 - gamma_mse_metric: 2.6773 - val_loss: 0.1850 - val_gamma_mse_metric: 78.3405 - lr: 2.0000e-04\n",
      "Epoch 7/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0598 - gamma_mse_metric: 2.0842 - val_loss: 0.1876 - val_gamma_mse_metric: 78.6128 - lr: 2.0000e-04\n",
      "Epoch 8/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0569 - gamma_mse_metric: 3.3870 - val_loss: 0.2020 - val_gamma_mse_metric: 174.4658 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "342/342 [==============================] - 31s 90ms/step - loss: 0.0583 - gamma_mse_metric: 1.8565 - val_loss: 0.1909 - val_gamma_mse_metric: 53.3310 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0535 - gamma_mse_metric: 3.6119 - val_loss: 0.1877 - val_gamma_mse_metric: 64.0205 - lr: 4.0000e-05\n",
      "Epoch 11/40\n",
      "342/342 [==============================] - 31s 89ms/step - loss: 0.0523 - gamma_mse_metric: 2.1348 - val_loss: 0.1906 - val_gamma_mse_metric: 79.9375 - lr: 4.0000e-05\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 33, 37, 16)           448       ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (Aver  (None, 16, 18, 16)           0         ['conv2d_25[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_25[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 16, 18, 32)           4640      ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (Aver  (None, 8, 9, 32)             0         ['conv2d_26[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_26[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 8, 9, 64)             18496     ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_27 (Aver  (None, 4, 4, 64)             0         ['conv2d_27[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_27[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 4, 4, 128)            73856     ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_28 (Aver  (None, 2, 2, 128)            0         ['conv2d_28[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 2, 2, 128)            512       ['average_pooling2d_28[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)         (None, 512)                  0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 512)                  0         ['flatten_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 256)                  131328    ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 17473)                4490561   ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 17473)                4490561   ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_31 (Dense)            (None, 17473)                4490561   ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_21 (Reshape)        (None, 1, 17473)             0         ['dense_29[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_22 (Reshape)        (None, 1, 17473)             0         ['dense_30[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_23 (Reshape)        (None, 1, 17473)             0         ['dense_31[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 3, 17473)             0         ['reshape_21[0][0]',          \n",
      " )                                                                   'reshape_22[0][0]',          \n",
      "                                                                     'reshape_23[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13701411 (52.27 MB)\n",
      "Trainable params: 13700931 (52.26 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 21s 116ms/step - loss: 0.2034 - gamma_mse_metric: 0.7903 - val_loss: 0.3436 - val_gamma_mse_metric: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 19s 112ms/step - loss: 0.0544 - gamma_mse_metric: 0.6417 - val_loss: 0.1872 - val_gamma_mse_metric: 0.5749 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 19s 113ms/step - loss: 0.0519 - gamma_mse_metric: 0.8192 - val_loss: 0.1932 - val_gamma_mse_metric: 0.7697 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 20s 116ms/step - loss: 0.0495 - gamma_mse_metric: 0.8050 - val_loss: 0.1818 - val_gamma_mse_metric: 0.7557 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0479 - gamma_mse_metric: 0.6824 - val_loss: 0.1784 - val_gamma_mse_metric: 0.9406 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 20s 114ms/step - loss: 0.0509 - gamma_mse_metric: 0.8065 - val_loss: 0.1641 - val_gamma_mse_metric: 1.0717 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 19s 113ms/step - loss: 0.0495 - gamma_mse_metric: 0.7842 - val_loss: 0.1774 - val_gamma_mse_metric: 1.8597 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 20s 116ms/step - loss: 0.0439 - gamma_mse_metric: 0.7147 - val_loss: 0.1619 - val_gamma_mse_metric: 1.6551 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 20s 116ms/step - loss: 0.0484 - gamma_mse_metric: 0.8151 - val_loss: 0.1672 - val_gamma_mse_metric: 4.0795 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0407 - gamma_mse_metric: 1.1085 - val_loss: 0.1697 - val_gamma_mse_metric: 8.2003 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 20s 116ms/step - loss: 0.0413 - gamma_mse_metric: 1.1152 - val_loss: 0.1590 - val_gamma_mse_metric: 3.4048 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "171/171 [==============================] - 19s 114ms/step - loss: 0.0446 - gamma_mse_metric: 0.9989 - val_loss: 0.1601 - val_gamma_mse_metric: 3.9047 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "171/171 [==============================] - 19s 113ms/step - loss: 0.0425 - gamma_mse_metric: 1.0413 - val_loss: 0.1661 - val_gamma_mse_metric: 7.1510 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0396 - gamma_mse_metric: 1.2291 - val_loss: 0.1580 - val_gamma_mse_metric: 1.9000 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "171/171 [==============================] - 19s 114ms/step - loss: 0.0401 - gamma_mse_metric: 0.9046 - val_loss: 0.1655 - val_gamma_mse_metric: 2.8457 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0432 - gamma_mse_metric: 0.9023 - val_loss: 0.1613 - val_gamma_mse_metric: 1.8746 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0387 - gamma_mse_metric: 0.8203 - val_loss: 0.1634 - val_gamma_mse_metric: 1.4396 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "171/171 [==============================] - 20s 115ms/step - loss: 0.0414 - gamma_mse_metric: 1.1880 - val_loss: 0.1703 - val_gamma_mse_metric: 4.3660 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "171/171 [==============================] - 20s 114ms/step - loss: 0.0342 - gamma_mse_metric: 1.1647 - val_loss: 0.1670 - val_gamma_mse_metric: 4.3700 - lr: 2.0000e-05\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 33, 37, 16)           2368      ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d_29 (Aver  (None, 16, 18, 16)           0         ['conv2d_29[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_29[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 16, 18, 32)           25120     ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_30 (Aver  (None, 8, 9, 32)             0         ['conv2d_30[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_30[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 8, 9, 64)             100416    ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_31 (Aver  (None, 4, 4, 64)             0         ['conv2d_31[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_31[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 4, 4, 128)            401536    ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_32 (Aver  (None, 2, 2, 128)            0         ['conv2d_32[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 2, 2, 128)            512       ['average_pooling2d_32[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 512)                  0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 512)                  0         ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 256)                  131328    ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dense_33 (Dense)            (None, 17473)                4490561   ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " dense_34 (Dense)            (None, 17473)                4490561   ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " dense_35 (Dense)            (None, 17473)                4490561   ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_24 (Reshape)        (None, 1, 17473)             0         ['dense_33[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_25 (Reshape)        (None, 1, 17473)             0         ['dense_34[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_26 (Reshape)        (None, 1, 17473)             0         ['dense_35[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 3, 17473)             0         ['reshape_24[0][0]',          \n",
      " )                                                                   'reshape_25[0][0]',          \n",
      "                                                                     'reshape_26[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14133411 (53.91 MB)\n",
      "Trainable params: 14132931 (53.91 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 30s 167ms/step - loss: 0.0903 - gamma_mse_metric: 1.0632 - val_loss: 0.2125 - val_gamma_mse_metric: 38896.8828 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0600 - gamma_mse_metric: 5.7936 - val_loss: 0.2107 - val_gamma_mse_metric: 1150617.0000 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 29s 168ms/step - loss: 0.0588 - gamma_mse_metric: 3.7301 - val_loss: 0.1752 - val_gamma_mse_metric: 69.3592 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 28s 164ms/step - loss: 0.0531 - gamma_mse_metric: 1.3920 - val_loss: 0.1866 - val_gamma_mse_metric: 61.6349 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 28s 164ms/step - loss: 0.0545 - gamma_mse_metric: 2.6868 - val_loss: 0.1758 - val_gamma_mse_metric: 48.5384 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 28s 163ms/step - loss: 0.0545 - gamma_mse_metric: 1.7089 - val_loss: 0.1603 - val_gamma_mse_metric: 9.7850 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 28s 162ms/step - loss: 0.0575 - gamma_mse_metric: 2.1083 - val_loss: 0.1805 - val_gamma_mse_metric: 1881.0743 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 28s 162ms/step - loss: 0.0517 - gamma_mse_metric: 1.8754 - val_loss: 0.1645 - val_gamma_mse_metric: 36992.6328 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 28s 162ms/step - loss: 0.0536 - gamma_mse_metric: 2.9582 - val_loss: 0.1749 - val_gamma_mse_metric: 112.5966 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "171/171 [==============================] - 28s 163ms/step - loss: 0.0387 - gamma_mse_metric: 2.4655 - val_loss: 0.1754 - val_gamma_mse_metric: 134.8942 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 28s 162ms/step - loss: 0.0370 - gamma_mse_metric: 5.1159 - val_loss: 0.1678 - val_gamma_mse_metric: 7.6391 - lr: 2.0000e-04\n",
      "Iteration 10/10\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 33, 37, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 33, 37, 16)           2368      ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " average_pooling2d_33 (Aver  (None, 16, 18, 16)           0         ['conv2d_33[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 16, 18, 16)           64        ['average_pooling2d_33[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 16, 18, 32)           25120     ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_34 (Aver  (None, 8, 9, 32)             0         ['conv2d_34[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 8, 9, 32)             128       ['average_pooling2d_34[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 8, 9, 64)             100416    ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_35 (Aver  (None, 4, 4, 64)             0         ['conv2d_35[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 4, 4, 64)             256       ['average_pooling2d_35[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 4, 4, 128)            401536    ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " average_pooling2d_36 (Aver  (None, 2, 2, 128)            0         ['conv2d_36[0][0]']           \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 2, 2, 128)            512       ['average_pooling2d_36[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)         (None, 512)                  0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 512)                  0         ['flatten_9[0][0]']           \n",
      "                                                                                                  \n",
      " dense_36 (Dense)            (None, 256)                  131328    ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " dense_37 (Dense)            (None, 17473)                4490561   ['dense_36[0][0]']            \n",
      "                                                                                                  \n",
      " dense_38 (Dense)            (None, 17473)                4490561   ['dense_36[0][0]']            \n",
      "                                                                                                  \n",
      " dense_39 (Dense)            (None, 17473)                4490561   ['dense_36[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_27 (Reshape)        (None, 1, 17473)             0         ['dense_37[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_28 (Reshape)        (None, 1, 17473)             0         ['dense_38[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_29 (Reshape)        (None, 1, 17473)             0         ['dense_39[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 3, 17473)             0         ['reshape_27[0][0]',          \n",
      " )                                                                   'reshape_28[0][0]',          \n",
      "                                                                     'reshape_29[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14133411 (53.91 MB)\n",
      "Trainable params: 14132931 (53.91 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "171/171 [==============================] - 30s 170ms/step - loss: 0.0917 - gamma_mse_metric: 1.0883 - val_loss: 0.2030 - val_gamma_mse_metric: 1599.8052 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0609 - gamma_mse_metric: 5.6073 - val_loss: 0.2227 - val_gamma_mse_metric: 20998.4922 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 28s 164ms/step - loss: 0.0627 - gamma_mse_metric: 5.0979 - val_loss: 0.1775 - val_gamma_mse_metric: 27.5671 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 28s 164ms/step - loss: 0.0582 - gamma_mse_metric: 329.4712 - val_loss: 0.1906 - val_gamma_mse_metric: 104.9380 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0573 - gamma_mse_metric: 127.6829 - val_loss: 0.1859 - val_gamma_mse_metric: 6.3164 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0586 - gamma_mse_metric: 2.8004 - val_loss: 0.1691 - val_gamma_mse_metric: 116.4298 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0618 - gamma_mse_metric: 2215.5466 - val_loss: 0.1952 - val_gamma_mse_metric: 6324.3604 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "171/171 [==============================] - 29s 167ms/step - loss: 0.0512 - gamma_mse_metric: 10.5650 - val_loss: 0.1795 - val_gamma_mse_metric: 461.2507 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "171/171 [==============================] - 28s 166ms/step - loss: 0.0565 - gamma_mse_metric: 6.2562 - val_loss: 0.1793 - val_gamma_mse_metric: 19.2226 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "171/171 [==============================] - 28s 166ms/step - loss: 0.0414 - gamma_mse_metric: 3.8040 - val_loss: 0.1807 - val_gamma_mse_metric: 27.0844 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "171/171 [==============================] - 29s 167ms/step - loss: 0.0405 - gamma_mse_metric: 4.0803 - val_loss: 0.1625 - val_gamma_mse_metric: 5.9488 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "171/171 [==============================] - 29s 167ms/step - loss: 0.0417 - gamma_mse_metric: 6.7951 - val_loss: 0.1765 - val_gamma_mse_metric: 8.5524 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "171/171 [==============================] - 28s 167ms/step - loss: 0.0419 - gamma_mse_metric: 5.1751 - val_loss: 0.1779 - val_gamma_mse_metric: 14.1596 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "171/171 [==============================] - 28s 167ms/step - loss: 0.0388 - gamma_mse_metric: 8.9785 - val_loss: 0.1756 - val_gamma_mse_metric: 16.7792 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "171/171 [==============================] - 29s 168ms/step - loss: 0.0360 - gamma_mse_metric: 7.6678 - val_loss: 0.1765 - val_gamma_mse_metric: 15.6716 - lr: 4.0000e-05\n",
      "Epoch 16/40\n",
      "171/171 [==============================] - 28s 165ms/step - loss: 0.0378 - gamma_mse_metric: 4.1956 - val_loss: 0.1749 - val_gamma_mse_metric: 10.2693 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Random search for hyperparameter tuning\n",
    "n_iterations = 10\n",
    "results = []\n",
    "best_val_mse = float(\"inf\")\n",
    "best_config = None\n",
    "best_model_weights = \"best_CNN_Gamma_weights_Taiwan-LearningCurve-10-2.h5\"\n",
    "\n",
    "# Log progress to a file to reduce notebook output\n",
    "log_file = \"hyperparameter_tuning_log.txt\"\n",
    "with open(log_file, \"w\") as log:\n",
    "    log.write(\"Hyperparameter Tuning Log\\n\")\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Limit print frequency\n",
    "    if i % 10 == 0 or i == n_iterations - 1:\n",
    "        print(f\"Iteration {i + 1}/{n_iterations}\")\n",
    "\n",
    "    # Log configuration details to file\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(f\"Iteration {i + 1}/{n_iterations}\\n\")\n",
    "    \n",
    "    # Randomly select hyperparameters\n",
    "    num_layers = random.choice(list(layer_neuron_map.keys()))\n",
    "    layer_filters = layer_neuron_map[num_layers]\n",
    "    kernel_size = random.choice(kernel_size_options)\n",
    "    learning_rate = random.choice(learning_rate_options)\n",
    "    dropout_rate = random.choice(dropout_options)\n",
    "    batch_size = random.choice(batch_size_options)\n",
    "\n",
    "    # Log configuration to file\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(f\"Testing configuration: layers={layer_filters}, kernel_size={kernel_size}, \"\n",
    "                  f\"learning_rate={learning_rate}, dropout_rate={dropout_rate}, batch_size={batch_size}\\n\")\n",
    "    \n",
    "    # Define model\n",
    "    cnn_gamma = complex_conv(\n",
    "        layer_filters=layer_filters,\n",
    "        bn=True,\n",
    "        padding='same',\n",
    "        kernel_size=kernel_size,\n",
    "        pooling=True,\n",
    "        dense_layers=[256],\n",
    "        dense_activation='relu',\n",
    "        input_shape=input_shape,\n",
    "        dropout=dropout_rate,\n",
    "        activation='relu',\n",
    "        output_shape=output_shape\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model_weights_name = f\"CNN_gamma_layers_{len(layer_filters)}_ksize_{kernel_size[0]}x{kernel_size[1]}_\" \\\n",
    "                         f\"lr_{learning_rate:.0e}_dropout_{dropout_rate}_batch_{batch_size}_Taiwan_LearningCurve.h5\"\n",
    "\n",
    "    # Train the model and track learning curves\n",
    "    history, trained_model = train_model(\n",
    "        cnn_gamma,\n",
    "        [x_train_np, y_train_np],\n",
    "        x_val=x_val_np,\n",
    "        y_val=y_val_np,\n",
    "        loss=gamma_loss_1d,\n",
    "        epochs=40,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        model_weights_name=model_weights_name,  # Provide a valid path here\n",
    "        metrics=gamma_mse_metric\n",
    "    )\n",
    "    \n",
    "    train_mse = history.history['gamma_mse_metric']\n",
    "    val_mse = history.history['val_gamma_mse_metric']\n",
    "\n",
    "    # Save trial results\n",
    "    results.append({\n",
    "        'config': {\n",
    "            'num_layers': len(layer_filters),\n",
    "            'kernel_size': kernel_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'batch_size': batch_size\n",
    "        },\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse\n",
    "    })\n",
    "\n",
    "    final_val_mse = val_mse[-1]\n",
    "    if final_val_mse < best_val_mse:\n",
    "        # Log new best model details\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"New best model found with val_mse={final_val_mse}\\n\")\n",
    "        best_val_mse = final_val_mse\n",
    "        best_config = {\n",
    "            'num_layers': len(layer_filters),\n",
    "            'kernel_size': kernel_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'batch_size': batch_size\n",
    "        }\n",
    "        trained_model.save_weights(best_model_weights)\n",
    "\n",
    "# Evaluate the best model's fit\n",
    "def evaluate_model_fit(train_mse, val_mse):\n",
    "    final_train_mse = train_mse[-1]\n",
    "    final_val_mse = val_mse[-1]\n",
    "\n",
    "    if abs(final_train_mse - final_val_mse) < 0.01 * final_train_mse:\n",
    "        return \"well-fitting\"\n",
    "    elif final_train_mse > final_val_mse:\n",
    "        return \"underfitting\"\n",
    "    else:\n",
    "        return \"overfitting\"\n",
    "\n",
    "# Log evaluation of the best model\n",
    "best_result = results[results.index(next(r for r in results if r['config'] == best_config))]\n",
    "best_fit_status = evaluate_model_fit(best_result['train_mse'], best_result['val_mse'])\n",
    "\n",
    "with open(log_file, \"a\") as log:\n",
    "    log.write(f\"The best model is {best_fit_status}.\\n\")\n",
    "\n",
    "if best_fit_status == \"underfitting\":\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(\"Recommendation: Increase model complexity or train longer.\\n\")\n",
    "elif best_fit_status == \"overfitting\":\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(\"Recommendation: Add regularization or simplify the model.\\n\")\n",
    "else:\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(\"The model is balanced and generalizes well.\\n\")\n",
    "\n",
    "# Plot learning curves for all configurations (after training to avoid intermediate plots)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for idx, result in enumerate(results):\n",
    "    plt.plot(result['train_mse'], label=f\"Train Config {idx+1}\")\n",
    "    plt.plot(result['val_mse'], label=f\"Val Config {idx+1}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.6, 1.05))\n",
    "plt.title(\"Learning Curves for Hyperparameter Tuning\")\n",
    "plt.savefig(\"Learning_Curves_Tuning_Taiwan-10-2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Avoid displaying plot in the notebook\n",
    "\n",
    "# Save results\n",
    "with open(\"CNN_gamma_hyperparameter_results_Taiwan-LearningCurve-10-2.json\", \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "with open(\"best_CNN_gamma_hyperparameters_Taiwan-LearningCurve-10-2.json\", \"w\") as f:\n",
    "    json.dump({'best_config': best_config, 'best_val_mse': best_val_mse, 'fit_status': best_fit_status}, f)\n",
    "\n",
    "# Log summary to file instead of printing in the notebook\n",
    "with open(log_file, \"a\") as log:\n",
    "    log.write(f\"Best hyperparameters saved: {best_config} with validation MSE: {best_val_mse}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714d6936-df75-4ce5-9e26-ba3c48f53656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'num_layers': 3, 'kernel_size': (7, 7), 'learning_rate': 1e-05, 'dropout_rate': 0.4, 'batch_size': 16}, 'train_mse': [0.8414599299430847, 0.7222318053245544, 0.6603160500526428, 0.6305774450302124, 0.6307864785194397, 0.6392927169799805, 0.6388553977012634, 0.6481098532676697, 0.649199366569519, 0.651633620262146, 0.6665406227111816, 0.6567527055740356, 0.6714462637901306], 'val_mse': [0.6922873854637146, 0.6139836311340332, 0.5349026322364807, 0.662743866443634, 1.0450408458709717, 0.9957059025764465, 1.1225143671035767, 1.3948264122009277, 2.292083501815796, 4.079450607299805, 3.7334251403808594, 3.467978000640869, 2.606809616088867]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plot learning curves for the BEST configuration ONLY \n",
    "# to see if the model with the best configuration is overfitting, underfitting, or well-fitting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Get the results for the best configuration\n",
    "best_result = results[results.index(next(r for r in results if r['config'] == best_config))] \n",
    "print(best_result)\n",
    "\n",
    "# Plot the training and validation MSE for the best configuration\n",
    "plt.plot(best_result['train_mse'], label=f\"Train (Best Config)\")  # Updated label\n",
    "plt.plot(best_result['val_mse'], label=f\"Validation (Best Config)\")  # Updated label\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')  # You might adjust the legend location\n",
    "plt.title(\"Learning Curves for Best Hyperparameter Configuration\")  # Updated title\n",
    "plt.savefig(\"Learning_Curves_Best_Config_Taiwan-10-2.png\", dpi=300, bbox_inches='tight')  # New filename\n",
    "#plt.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (high_res_env)",
   "language": "python",
   "name": "high_res_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
